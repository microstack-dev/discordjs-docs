# Large Bots

Discord.js v14.25.1 scaling strategies for large-scale Discord bots serving 1000+ servers. This section covers architecture patterns, resource optimization, monitoring, and operational practices for enterprise-scale bots.

## Scaling Architecture

Strategies for handling large bot deployments.

### Multi-Process Architecture

```js
// master.js - Main process manager
const { ShardingManager } = require('discord.js')
const { createLogger } = require('./logger')
const { MetricsCollector } = require('./metrics')

class BotMaster {
  constructor() {
    this.logger = createLogger('Master')
    this.metrics = new MetricsCollector()
    this.manager = null

    this.setupProcessManagement()
    this.startShardingManager()
  }

  setupProcessManagement() {
    process.on('SIGINT', () => this.gracefulShutdown())
    process.on('SIGTERM', () => this.gracefulShutdown())

    // Handle uncaught exceptions
    process.on('uncaughtException', (error) => {
      this.logger.error('Uncaught exception:', error)
      this.gracefulShutdown(1)
    })

    process.on('unhandledRejection', (reason, promise) => {
      this.logger.error('Unhandled rejection at:', promise, 'reason:', reason)
    })
  }

  startShardingManager() {
    this.manager = new ShardingManager('./bot.js', {
      token: process.env.DISCORD_TOKEN,
      totalShards: 'auto',
      shardList: 'auto',
      mode: 'process',
      respawn: true,
      timeout: 60000
    })

    this.manager.on('shardCreate', (shard) => {
      this.logger.info(`Launched shard ${shard.id}`)
      this.metrics.recordShardCreate(shard.id)

      shard.on('ready', () => {
        this.logger.info(`Shard ${shard.id} ready`)
        this.metrics.recordShardReady(shard.id)
      })

      shard.on('disconnect', () => {
        this.logger.warn(`Shard ${shard.id} disconnected`)
        this.metrics.recordShardDisconnect(shard.id)
      })

      shard.on('death', (process) => {
        this.logger.error(`Shard ${shard.id} died with code ${process.exitCode}`)
        this.metrics.recordShardDeath(shard.id, process.exitCode)
      })
    })

    this.manager.spawn()
  }

  gracefulShutdown(code = 0) {
    this.logger.info('Initiating graceful shutdown...')

    if (this.manager) {
      this.manager.broadcastEval(() => {
        // Clean shutdown logic in shards
        process.exit(0)
      }).then(() => {
        this.manager.destroy()
        process.exit(code)
      }).catch(() => {
        process.exit(code)
      })
    } else {
      process.exit(code)
    }
  }
}

if (require.main === module) {
  new BotMaster()
}
```

### Database Sharding

```js
class DatabaseShardManager {
  constructor() {
    this.shards = new Map()
    this.shardCount = 4  // Number of database shards
    this.setupShards()
  }

  setupShards() {
    for (let i = 0; i < this.shardCount; i++) {
      const connection = this.createShardConnection(i)
      this.shards.set(i, connection)
    }
  }

  createShardConnection(shardId) {
    // Create database connection for this shard
    // Implementation depends on your database choice
    return {
      id: shardId,
      connection: null,  // Your database connection
      guilds: new Set()
    }
  }

  getShardId(guildId) {
    // Simple modulo-based sharding
    return parseInt(guildId) % this.shardCount
  }

  getShard(guildId) {
    const shardId = this.getShardId(guildId)
    return this.shards.get(shardId)
  }

  async executeOnShard(guildId, operation) {
    const shard = this.getShard(guildId)

    if (!shard) {
      throw new Error(`No shard found for guild ${guildId}`)
    }

    return await operation(shard.connection)
  }

  async migrateGuild(guildId, fromShardId, toShardId) {
    // Handle guild migration between shards
    const fromShard = this.shards.get(fromShardId)
    const toShard = this.shards.get(toShardId)

    // Migration logic here
    console.log(`Migrating guild ${guildId} from shard ${fromShardId} to ${toShardId}`)
  }
}
```

## Resource Optimization

Efficient resource usage for large-scale operations.

### Connection Pooling

```js
class ConnectionPoolManager {
  constructor(options = {}) {
    this.maxConnections = options.maxConnections || 100
    this.minConnections = options.minConnections || 10
    this.acquireTimeout = options.acquireTimeout || 30000
    this.idleTimeout = options.idleTimeout || 600000  // 10 minutes

    this.pool = []
    this.available = []
    this.waitingQueue = []
    this.stats = {
      created: 0,
      destroyed: 0,
      acquired: 0,
      released: 0,
      waiting: 0,
      idle: 0
    }
  }

  async acquire() {
    return new Promise((resolve, reject) => {
      const timeout = setTimeout(() => {
        const index = this.waitingQueue.indexOf(resolve)
        if (index > -1) {
          this.waitingQueue.splice(index, 1)
          this.stats.waiting--
          reject(new Error('Connection acquire timeout'))
        }
      }, this.acquireTimeout)

      if (this.available.length > 0) {
        const connection = this.available.pop()
        clearTimeout(timeout)
        this.stats.acquired++
        resolve(connection)
        return
      }

      if (this.pool.length < this.maxConnections) {
        const connection = this.createConnection()
        this.pool.push(connection)
        this.available.push(connection)
        clearTimeout(timeout)
        this.stats.acquired++
        resolve(connection)
        return
      }

      this.waitingQueue.push(resolve)
      this.stats.waiting++
    })
  }

  release(connection) {
    if (this.waitingQueue.length > 0) {
      const waitingResolve = this.waitingQueue.shift()
      this.stats.waiting--
      this.stats.acquired++
      waitingResolve(connection)
    } else {
      this.available.push(connection)
      this.stats.idle++
    }
  }

  createConnection() {
    this.stats.created++
    // Create actual connection (database, Redis, etc.)
    return {
      id: this.stats.created,
      created: Date.now(),
      lastUsed: Date.now()
    }
  }

  cleanup() {
    const now = Date.now()
    const idleConnections = this.available.filter(conn =>
      now - conn.lastUsed > this.idleTimeout
    )

    idleConnections.forEach(conn => {
      const index = this.available.indexOf(conn)
      if (index > -1) {
        this.available.splice(index, 1)
        this.pool.splice(this.pool.indexOf(conn), 1)
        this.stats.destroyed++
      }
    })
  }

  getStats() {
    return {
      ...this.stats,
      total: this.pool.length,
      available: this.available.length,
      waiting: this.waitingQueue.length
    }
  }
}
```

### Cache Hierarchy

```js
class HierarchicalCache {
  constructor() {
    // L1: Memory cache (fastest, smallest)
    this.l1Cache = new Map()

    // L2: Redis cache (medium speed, larger)
    this.l2Cache = null  // Redis client

    // L3: Database (slowest, largest)
    this.database = null

    this.stats = {
      l1Hits: 0,
      l1Misses: 0,
      l2Hits: 0,
      l2Misses: 0,
      dbHits: 0,
      dbMisses: 0
    }
  }

  async get(key) {
    // Check L1 cache
    if (this.l1Cache.has(key)) {
      this.stats.l1Hits++
      return this.l1Cache.get(key)
    }

    this.stats.l1Misses++

    // Check L2 cache
    if (this.l2Cache) {
      try {
        const l2Value = await this.l2Cache.get(key)
        if (l2Value) {
          this.stats.l2Hits++
          this.l1Cache.set(key, l2Value)  // Promote to L1
          return l2Value
        }
      } catch (error) {
        console.error('L2 cache error:', error)
      }
    }

    this.stats.l2Misses++

    // Check database
    try {
      const dbValue = await this.database.get(key)
      if (dbValue) {
        this.stats.dbHits++
        // Cache in L2 and L1
        if (this.l2Cache) {
          await this.l2Cache.set(key, dbValue)
        }
        this.l1Cache.set(key, dbValue)
        return dbValue
      }
    } catch (error) {
      console.error('Database error:', error)
    }

    this.stats.dbMisses++
    return null
  }

  async set(key, value, ttl) {
    // Set in all levels
    this.l1Cache.set(key, value)

    if (this.l2Cache) {
      await this.l2Cache.set(key, value, ttl)
    }

    await this.database.set(key, value, ttl)
  }

  async invalidate(key) {
    this.l1Cache.delete(key)

    if (this.l2Cache) {
      await this.l2Cache.del(key)
    }

    await this.database.delete(key)
  }

  getStats() {
    const totalRequests = this.stats.l1Hits + this.stats.l1Misses
    return {
      ...this.stats,
      l1HitRate: totalRequests > 0 ? this.stats.l1Hits / totalRequests : 0,
      l2HitRate: this.stats.l2Misses > 0 ? this.stats.l2Hits / (this.stats.l2Hits + this.stats.l2Misses) : 0
    }
  }
}
```

## Performance Monitoring

Comprehensive monitoring for large-scale deployments.

### Distributed Metrics Collection

```js
class DistributedMetricsCollector {
  constructor() {
    this.metrics = new Map()
    this.aggregationInterval = 60000  // 1 minute
    this.retentionPeriod = 24 * 60 * 60 * 1000  // 24 hours

    this.startAggregation()
  }

  recordMetric(shardId, metricName, value, tags = {}) {
    const key = `${shardId}:${metricName}`
    const timestamp = Date.now()

    if (!this.metrics.has(key)) {
      this.metrics.set(key, [])
    }

    const metricData = this.metrics.get(key)
    metricData.push({
      value,
      timestamp,
      tags,
      shardId
    })

    // Keep only recent data
    this.cleanupOldMetrics(key)
  }

  cleanupOldMetrics(key) {
    const metricData = this.metrics.get(key)
    const cutoff = Date.now() - this.retentionPeriod

    const filtered = metricData.filter(point => point.timestamp > cutoff)
    this.metrics.set(key, filtered)
  }

  getAggregatedMetrics(metricName, timeRange = 3600000) {  // 1 hour
    const cutoff = Date.now() - timeRange
    const aggregated = {}

    for (const [key, data] of this.metrics) {
      if (key.endsWith(`:${metricName}`)) {
        const recentData = data.filter(point => point.timestamp > cutoff)

        if (recentData.length > 0) {
          const shardId = key.split(':')[0]
          aggregated[shardId] = {
            count: recentData.length,
            sum: recentData.reduce((sum, point) => sum + point.value, 0),
            avg: recentData.reduce((sum, point) => sum + point.value, 0) / recentData.length,
            min: Math.min(...recentData.map(point => point.value)),
            max: Math.max(...recentData.map(point => point.value))
          }
        }
      }
    }

    return aggregated
  }

  startAggregation() {
    setInterval(() => {
      this.aggregateAndReport()
    }, this.aggregationInterval)
  }

  aggregateAndReport() {
    const report = {
      timestamp: Date.now(),
      shards: this.getAggregatedMetrics('guilds'),
      performance: this.getAggregatedMetrics('responseTime'),
      errors: this.getAggregatedMetrics('errors'),
      memory: this.getAggregatedMetrics('memoryUsage')
    }

    // Send to monitoring system (Prometheus, DataDog, etc.)
    this.sendToMonitoring(report)
  }

  sendToMonitoring(report) {
    // Implementation depends on your monitoring solution
    console.log('Metrics report:', JSON.stringify(report, null, 2))
  }
}
```

### Health Checks

```js
class HealthChecker {
  constructor(client, options = {}) {
    this.client = client
    this.checkInterval = options.checkInterval || 30000
    this.unhealthyThreshold = options.unhealthyThreshold || 3
    this.consecutiveFailures = 0

    this.checks = [
      this.checkDiscordConnectivity.bind(this),
      this.checkDatabaseConnectivity.bind(this),
      this.checkRedisConnectivity.bind(this),
      this.checkMemoryUsage.bind(this),
      this.checkShardHealth.bind(this)
    ]
  }

  startHealthChecks() {
    setInterval(() => {
      this.performHealthChecks()
    }, this.checkInterval)
  }

  async performHealthChecks() {
    const results = await Promise.allSettled(
      this.checks.map(check => check())
    )

    const failures = results.filter(result => result.status === 'rejected')

    if (failures.length > 0) {
      this.consecutiveFailures++
      console.warn(`Health check failures: ${failures.length}/${this.checks.length}`)

      failures.forEach((failure, index) => {
        console.warn(`Check ${index} failed:`, failure.reason)
      })
    } else {
      this.consecutiveFailures = 0
    }

    if (this.consecutiveFailures >= this.unhealthyThreshold) {
      this.handleUnhealthyState()
    }
  }

  async checkDiscordConnectivity() {
    if (!this.client.ws || this.client.ws.status !== 0) {
      throw new Error('Discord WebSocket not connected')
    }
  }

  async checkDatabaseConnectivity() {
    // Check database connection
    // Implementation depends on your database
  }

  async checkRedisConnectivity() {
    // Check Redis connection
    // Implementation depends on your Redis setup
  }

  async checkMemoryUsage() {
    const memUsage = process.memoryUsage()
    const heapUsedPercent = (memUsage.heapUsed / memUsage.heapTotal) * 100

    if (heapUsedPercent > 90) {
      throw new Error(`High memory usage: ${heapUsedPercent.toFixed(1)}%`)
    }
  }

  async checkShardHealth() {
    if (this.client.shard) {
      const ping = await this.client.shard.broadcastEval(() => true)
      if (ping.filter(Boolean).length !== this.client.shard.count) {
        throw new Error('Some shards are unresponsive')
      }
    }
  }

  handleUnhealthyState() {
    console.error('ðŸš¨ SERVICE UNHEALTHY - Initiating recovery procedures')

    // Send alert to monitoring system
    this.sendAlert('Service unhealthy', {
      consecutiveFailures: this.consecutiveFailures,
      timestamp: Date.now()
    })

    // Attempt recovery
    this.attemptRecovery()
  }

  sendAlert(title, details) {
    // Send to alerting system (Slack, PagerDuty, etc.)
    console.error(`ALERT: ${title}`, details)
  }

  async attemptRecovery() {
    // Implement recovery logic
    // - Restart unhealthy shards
    // - Reconnect to databases
    // - Clear caches if needed
    console.log('Attempting automatic recovery...')
  }
}
```

## Incident Response

Handling incidents in large-scale deployments.

### Incident Detection

```js
class IncidentDetector {
  constructor(thresholds = {}) {
    this.thresholds = {
      errorRate: thresholds.errorRate || 0.05,  // 5% error rate
      responseTime: thresholds.responseTime || 5000,  // 5 seconds
      memorySpike: thresholds.memorySpike || 100 * 1024 * 1024,  // 100MB spike
      shardDisconnects: thresholds.shardDisconnects || 3  // 3+ shard disconnects
    }

    this.incidents = []
    this.activeIncident = null
  }

  detectIncident(metrics) {
    const issues = []

    if (metrics.errorRate > this.thresholds.errorRate) {
      issues.push({
        type: 'high_error_rate',
        severity: 'critical',
        message: `Error rate: ${(metrics.errorRate * 100).toFixed(1)}%`
      })
    }

    if (metrics.avgResponseTime > this.thresholds.responseTime) {
      issues.push({
        type: 'high_response_time',
        severity: 'warning',
        message: `Average response time: ${metrics.avgResponseTime.toFixed(0)}ms`
      })
    }

    if (metrics.memorySpike > this.thresholds.memorySpike) {
      issues.push({
        type: 'memory_spike',
        severity: 'warning',
        message: `Memory spike: ${this.formatBytes(metrics.memorySpike)}`
      })
    }

    if (metrics.shardDisconnects >= this.thresholds.shardDisconnects) {
      issues.push({
        type: 'shard_instability',
        severity: 'critical',
        message: `Shard disconnects: ${metrics.shardDisconnects}`
      })
    }

    if (issues.length > 0) {
      this.createIncident(issues)
    }
  }

  createIncident(issues) {
    if (this.activeIncident) {
      // Update existing incident
      this.activeIncident.issues.push(...issues)
      this.activeIncident.lastUpdate = Date.now()
    } else {
      // Create new incident
      this.activeIncident = {
        id: `incident_${Date.now()}`,
        startTime: Date.now(),
        lastUpdate: Date.now(),
        issues,
        status: 'active',
        severity: this.calculateSeverity(issues)
      }

      this.notifyIncident(this.activeIncident)
    }
  }

  calculateSeverity(issues) {
    if (issues.some(issue => issue.severity === 'critical')) {
      return 'critical'
    }
    if (issues.some(issue => issue.severity === 'warning')) {
      return 'warning'
    }
    return 'info'
  }

  resolveIncident() {
    if (this.activeIncident) {
      this.activeIncident.status = 'resolved'
      this.activeIncident.endTime = Date.now()
      this.incidents.push(this.activeIncident)
      this.activeIncident = null

      this.notifyResolution()
    }
  }

  notifyIncident(incident) {
    console.error('ðŸš¨ INCIDENT DETECTED:', incident.id)
    console.error('Severity:', incident.severity)
    console.error('Issues:')
    incident.issues.forEach(issue => {
      console.error(`  - ${issue.message}`)
    })

    // Send to incident management system
  }

  notifyResolution() {
    console.log('âœ… Incident resolved')
  }

  formatBytes(bytes) {
    const units = ['B', 'KB', 'MB', 'GB']
    let value = bytes
    let unitIndex = 0

    while (value >= 1024 && unitIndex < units.length - 1) {
      value /= 1024
      unitIndex++
    }

    return `${value.toFixed(2)} ${units[unitIndex]}`
  }
}
```

### Automated Recovery

```js
class AutomatedRecovery {
  constructor(client) {
    this.client = client
    this.recoveryStrategies = {
      shard_disconnect: this.recoverShardDisconnect.bind(this),
      memory_pressure: this.recoverMemoryPressure.bind(this),
      high_error_rate: this.recoverHighErrorRate.bind(this),
      database_connection: this.recoverDatabaseConnection.bind(this)
    }
  }

  async executeRecovery(incidentType) {
    const strategy = this.recoveryStrategies[incidentType]

    if (!strategy) {
      console.error(`No recovery strategy for ${incidentType}`)
      return false
    }

    try {
      console.log(`Executing recovery strategy: ${incidentType}`)
      const success = await strategy()
      console.log(`Recovery ${success ? 'successful' : 'failed'} for ${incidentType}`)
      return success
    } catch (error) {
      console.error(`Recovery failed for ${incidentType}:`, error)
      return false
    }
  }

  async recoverShardDisconnect() {
    if (this.client.shard) {
      const unhealthyShards = await this.client.shard.broadcastEval(() => {
        return {
          id: this.shardId,
          ping: this.ping,
          status: this.status
        }
      })

      for (const shard of unhealthyShards) {
        if (shard.status !== 'ready') {
          await this.client.shard.broadcastEval((id) => {
            if (this.shardId === id) {
              this.destroy()
            }
          }, shard.id)

          // Wait for respawn
          await new Promise(resolve => setTimeout(resolve, 5000))
        }
      }
    }

    return true
  }

  async recoverMemoryPressure() {
    // Force garbage collection
    if (global.gc) {
      global.gc()
    }

    // Clear caches
    this.clearApplicationCaches()

    // Restart problematic shards if needed
    return true
  }

  async recoverHighErrorRate() {
    // Implement circuit breaker
    this.enableCircuitBreaker()

    // Scale up if possible
    await this.attemptScaling()

    return true
  }

  async recoverDatabaseConnection() {
    // Reconnect to database
    await this.reconnectDatabase()

    // Retry pending operations
    await this.retryPendingOperations()

    return true
  }

  clearApplicationCaches() {
    // Clear bot-specific caches
    console.log('Clearing application caches...')
  }

  enableCircuitBreaker() {
    // Implement circuit breaker pattern
    console.log('Enabling circuit breaker...')
  }

  async attemptScaling() {
    // Scale up shards or resources
    console.log('Attempting to scale up...')
  }

  async reconnectDatabase() {
    // Database reconnection logic
    console.log('Reconnecting to database...')
  }

  async retryPendingOperations() {
    // Retry failed operations
    console.log('Retrying pending operations...')
  }
}
```

## Maintenance Strategies

Ongoing maintenance for large-scale bots.

### Rolling Deployments

```js
class RollingDeployer {
  constructor(manager) {
    this.manager = manager
    this.updateInterval = 30000  // 30 seconds between shard updates
    this.maxConcurrentUpdates = 2
  }

  async deployUpdate(newCodePath) {
    console.log('Starting rolling deployment...')

    const totalShards = this.manager.totalShards
    const batches = this.createBatches(totalShards, this.maxConcurrentUpdates)

    for (const batch of batches) {
      console.log(`Updating batch: ${batch.join(', ')}`)

      const updatePromises = batch.map(shardId =>
        this.updateShard(shardId, newCodePath)
      )

      await Promise.all(updatePromises)
      await this.waitForStability()
    }

    console.log('Rolling deployment completed')
  }

  createBatches(totalShards, batchSize) {
    const batches = []

    for (let i = 0; i < totalShards; i += batchSize) {
      batches.push(Array.from({ length: Math.min(batchSize, totalShards - i) }, (_, j) => i + j))
    }

    return batches
  }

  async updateShard(shardId, newCodePath) {
    try {
      // Send update signal to shard
      await this.manager.broadcastEval((id, codePath) => {
        if (this.shardId === id) {
          // Load new code
          require(codePath)
          console.log(`Shard ${id} updated`)
        }
      }, shardId, newCodePath)

      console.log(`Shard ${shardId} updated successfully`)
    } catch (error) {
      console.error(`Failed to update shard ${shardId}:`, error)
      throw error
    }
  }

  async waitForStability() {
    // Wait for shards to stabilize
    await new Promise(resolve => setTimeout(resolve, this.updateInterval))

    // Check shard health
    const healthChecks = await this.manager.broadcastEval(() => ({
      ready: this.ready,
      guilds: this.guilds.cache.size
    }))

    const unhealthyShards = healthChecks.filter((check, index) => !check.ready)

    if (unhealthyShards.length > 0) {
      console.warn(`Unhealthy shards after update: ${unhealthyShards.length}`)
      // Handle unhealthy shards
    }
  }
}
```

### Database Maintenance

```js
class DatabaseMaintenance {
  constructor() {
    this.maintenanceWindow = {
      start: 2,  // 2 AM
      end: 4     // 4 AM
    }
    this.maintenanceTasks = [
      this.optimizeTables.bind(this),
      this.updateIndexes.bind(this),
      this.cleanupOldData.bind(this),
      this.backupDatabase.bind(this)
    ]
  }

  startScheduledMaintenance() {
    const now = new Date()
    const nextMaintenance = new Date(now.getFullYear(), now.getMonth(), now.getDate() + 1, this.maintenanceWindow.start)

    const timeUntilMaintenance = nextMaintenance - now

    setTimeout(() => {
      this.runMaintenance()
      // Schedule next maintenance
      setInterval(() => {
        this.runMaintenance()
      }, 24 * 60 * 60 * 1000)
    }, timeUntilMaintenance)
  }

  async runMaintenance() {
    console.log('Starting scheduled database maintenance...')

    try {
      for (const task of this.maintenanceTasks) {
        await task()
      }

      console.log('Database maintenance completed successfully')
    } catch (error) {
      console.error('Database maintenance failed:', error)
      // Send alert
    }
  }

  async optimizeTables() {
    // Optimize database tables
    console.log('Optimizing tables...')
    // Implementation depends on database
  }

  async updateIndexes() {
    // Update and rebuild indexes
    console.log('Updating indexes...')
    // Implementation depends on database
  }

  async cleanupOldData() {
    // Clean up old logs, cache entries, etc.
    console.log('Cleaning up old data...')
    // Remove data older than retention period
  }

  async backupDatabase() {
    // Create database backup
    console.log('Creating database backup...')
    // Implementation depends on database and backup strategy
  }
}
```

### Capacity Planning

```js
class CapacityPlanner {
  constructor() {
    this.metrics = new Map()
    this.growthThreshold = 0.8  // 80% capacity
    this.planningInterval = 7 * 24 * 60 * 60 * 1000  // Weekly
  }

  recordUsage(metric, value) {
    if (!this.metrics.has(metric)) {
      this.metrics.set(metric, [])
    }

    const data = this.metrics.get(metric)
    data.push({
      value,
      timestamp: Date.now()
    })

    // Keep 30 days of data
    const thirtyDaysAgo = Date.now() - 30 * 24 * 60 * 60 * 1000
    const filtered = data.filter(point => point.timestamp > thirtyDaysAgo)
    this.metrics.set(metric, filtered)
  }

  analyzeCapacity() {
    const analysis = {}

    for (const [metric, data] of this.metrics) {
      if (data.length < 7) continue  // Need at least a week of data

      const recent = data.slice(-7)  // Last 7 days
      const currentAvg = recent.reduce((sum, point) => sum + point.value, 0) / recent.length

      // Calculate trend
      const trend = this.calculateTrend(data)

      analysis[metric] = {
        currentAverage: currentAvg,
        trend,
        projectedCapacity: this.projectCapacity(currentAvg, trend),
        needsScaling: currentAvg > this.growthThreshold
      }
    }

    return analysis
  }

  calculateTrend(data) {
    if (data.length < 14) return 0

    const firstHalf = data.slice(0, Math.floor(data.length / 2))
    const secondHalf = data.slice(Math.floor(data.length / 2))

    const firstAvg = firstHalf.reduce((sum, point) => sum + point.value, 0) / firstHalf.length
    const secondAvg = secondHalf.reduce((sum, point) => sum + point.value, 0) / secondHalf.length

    return (secondAvg - firstAvg) / firstAvg  // Growth rate
  }

  projectCapacity(current, trend, days = 30) {
    // Simple linear projection
    return current * (1 + trend * (days / 30))
  }

  generateScalingRecommendations() {
    const analysis = this.analyzeCapacity()
    const recommendations = []

    for (const [metric, data] of Object.entries(analysis)) {
      if (data.needsScaling) {
        recommendations.push({
          metric,
          action: 'scale_up',
          reason: `${metric} at ${(data.currentAverage * 100).toFixed(1)}% capacity`,
          projected: data.projectedCapacity
        })
      }
    }

    return recommendations
  }

  startCapacityPlanning() {
    setInterval(() => {
      const recommendations = this.generateScalingRecommendations()

      if (recommendations.length > 0) {
        console.log('ðŸš¨ Capacity planning recommendations:')
        recommendations.forEach(rec => {
          console.log(`  - ${rec.metric}: ${rec.reason}`)
        })

        // Send to planning system
      }
    }, this.planningInterval)
  }
}
```

## Best Practices

### Implementation Guidelines

1. **Use multi-process architecture** with ShardingManager for horizontal scaling
2. **Implement database sharding** for large datasets
3. **Use connection pooling** to manage database connections efficiently
4. **Implement hierarchical caching** (memory â†’ Redis â†’ database)
5. **Set up comprehensive monitoring** with distributed metrics collection
6. **Implement health checks** and automated incident response
7. **Use rolling deployments** for zero-downtime updates
8. **Perform regular maintenance** during low-traffic windows
9. **Monitor capacity usage** and plan for scaling
10. **Implement automated recovery** procedures

### Production Considerations

```js
// Complete large bot management system
class EnterpriseBotManager {
  constructor(client) {
    this.client = client

    // Core systems
    this.shardManager = new ShardingManager(client)
    this.dbShardManager = new DatabaseShardManager()
    this.connectionPool = new ConnectionPoolManager()
    this.hierarchicalCache = new HierarchicalCache()

    // Monitoring & health
    this.metricsCollector = new DistributedMetricsCollector()
    this.healthChecker = new HealthChecker(client)
    this.incidentDetector = new IncidentDetector()

    // Operations
    this.rollingDeployer = new RollingDeployer(this.shardManager)
    this.databaseMaintenance = new DatabaseMaintenance()
    this.capacityPlanner = new CapacityPlanner()
    this.automatedRecovery = new AutomatedRecovery(client)

    this.initializeSystems()
  }

  initializeSystems() {
    // Start all monitoring systems
    this.healthChecker.startHealthChecks()
    this.capacityPlanner.startCapacityPlanning()
    this.databaseMaintenance.startScheduledMaintenance()

    // Set up incident response
    this.setupIncidentResponse()

    console.log('Enterprise bot management system initialized')
  }

  setupIncidentResponse() {
    // Integrate incident detection with automated recovery
    setInterval(() => {
      const metrics = this.metricsCollector.getCurrentMetrics()
      const incidents = this.incidentDetector.detectIncident(metrics)

      if (incidents && incidents.length > 0) {
        incidents.forEach(incident => {
          this.automatedRecovery.executeRecovery(incident.type)
        })
      }
    }, 60000)  // Check every minute
  }

  getSystemStatus() {
    return {
      shards: this.shardManager.getStatus(),
      database: this.dbShardManager.getStatus(),
      connections: this.connectionPool.getStats(),
      cache: this.hierarchicalCache.getStats(),
      health: this.healthChecker.getStatus(),
      incidents: this.incidentDetector.getActiveIncidents()
    }
  }

  async gracefulShutdown() {
    console.log('Initiating enterprise bot shutdown...')

    // Shutdown in reverse order
    await this.connectionPool.closeAll()
    await this.hierarchicalCache.close()
    await this.dbShardManager.close()
    await this.shardManager.destroy()

    console.log('Enterprise bot shutdown complete')
  }
}
```

This comprehensive approach ensures your large-scale Discord bot can handle thousands of servers with optimal performance, reliability, and maintainability in production environments.